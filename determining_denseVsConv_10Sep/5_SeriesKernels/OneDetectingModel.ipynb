{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from tensorflow.keras.callbacks import Callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the dataset\n",
    "mnist = keras.datasets.mnist\n",
    "(x_full, y_full), (x_test_full, y_test_full) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape_training_0 =>\n",
      "\t (5400, 28, 28)\n",
      "\t (5400,)\n",
      "lenght_training_other =>\n",
      "\t 9 9\n",
      "shape_training_other =>\n",
      "\t (5400, 28, 28)\n",
      "\t (5400,)\n",
      "shape_training_complete =>\n",
      "\t (10800, 28, 28)\n",
      "\t (10800,)\n"
     ]
    }
   ],
   "source": [
    "# Training Data\n",
    "'''\n",
    "TRAINING DATA\n",
    "5400 - oness\n",
    "5400 - other \n",
    "    [600 * 9 of 1/0 to 9]\n",
    "'''\n",
    "\n",
    "x_train_0 = x_full[y_full == 1][:5400]\n",
    "y_train_0 = np.ones((5400,))\n",
    "print(\"shape_training_0 =>\")\n",
    "print(\"\\t\",x_train_0.shape)\n",
    "print(\"\\t\",y_train_0.shape)\n",
    "\n",
    "x_train_others = []\n",
    "y_train_others = []\n",
    "\n",
    "x_digit = x_full[y_full == 0][:600]\n",
    "y_digit = np.zeros((600,))  \n",
    "x_train_others.append(x_digit)\n",
    "y_train_others.append(y_digit)\n",
    "\n",
    "for digit in range(2,10):\n",
    "    x_digit = x_full[y_full == digit][:600]\n",
    "    y_digit = np.zeros((600,))  \n",
    "    x_train_others.append(x_digit)\n",
    "    y_train_others.append(y_digit)\n",
    "print(\"lenght_training_other =>\")\n",
    "print(\"\\t\",len(x_train_others),len(y_train_others))\n",
    "\n",
    "x_train_others = np.concatenate(x_train_others, axis=0)\n",
    "y_train_others = np.concatenate(y_train_others, axis=0)\n",
    "print(\"shape_training_other =>\")\n",
    "print(\"\\t\",x_train_others.shape)\n",
    "print(\"\\t\",y_train_others.shape)\n",
    "\n",
    "x_train = np.concatenate([x_train_0, x_train_others], axis=0)\n",
    "y_train = np.concatenate([y_train_0, y_train_others], axis=0)\n",
    "x_train, y_train = shuffle(x_train, y_train, random_state=42)\n",
    "print(\"shape_training_complete =>\")\n",
    "print(\"\\t\",x_train.shape)\n",
    "print(\"\\t\",y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape_testing_0 =>\n",
      "\t (810, 28, 28)\n",
      "\t (810,)\n",
      "lenght_testing_other =>\n",
      "\t 9 9\n",
      "shape_testing_other =>\n",
      "\t (810, 28, 28)\n",
      "\t (810,)\n",
      "shape_testing_complete =>\n",
      "\t (1620, 28, 28)\n",
      "\t (1620,)\n"
     ]
    }
   ],
   "source": [
    "# Testing Data\n",
    "'''\n",
    "TESTING DATA\n",
    "810 - ones\n",
    "810 - other \n",
    "    [90 * 9 of 1/0 to 9]\n",
    "'''\n",
    "\n",
    "x_test_0 = x_test_full[y_test_full == 1][:810]\n",
    "y_test_0 = np.ones((810,))\n",
    "print(\"shape_testing_0 =>\")\n",
    "print(\"\\t\",x_test_0.shape)\n",
    "print(\"\\t\",y_test_0.shape)\n",
    "\n",
    "x_test_others = []\n",
    "y_test_others = []\n",
    "x_digit = x_test_full[y_test_full == 0][:90]\n",
    "y_digit = np.zeros((90,))  \n",
    "x_test_others.append(x_digit)\n",
    "y_test_others.append(y_digit)\n",
    "for digit in range(2,10):\n",
    "    x_digit = x_test_full[y_test_full == digit][:90]\n",
    "    y_digit = np.zeros((90,))  \n",
    "    x_test_others.append(x_digit)\n",
    "    y_test_others.append(y_digit)\n",
    "print(\"lenght_testing_other =>\")\n",
    "print(\"\\t\",len(x_test_others),len(y_test_others))\n",
    "\n",
    "x_test_others = np.concatenate(x_test_others, axis=0)\n",
    "y_test_others = np.concatenate(y_test_others, axis=0)\n",
    "print(\"shape_testing_other =>\")\n",
    "print(\"\\t\",x_test_others.shape)\n",
    "print(\"\\t\",y_test_others.shape)\n",
    "\n",
    "\n",
    "x_test = np.concatenate([x_test_0, x_test_others], axis=0)\n",
    "y_test = np.concatenate([y_test_0, y_test_others], axis=0)\n",
    "x_test, y_test = shuffle(x_test, y_test, random_state=42)\n",
    "print(\"shape_testing_complete =>\")\n",
    "print(\"\\t\",x_test.shape)\n",
    "print(\"\\t\",y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_26 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │            \u001b[38;5;34m10\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_27 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │            \u001b[38;5;34m10\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_28 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │            \u001b[38;5;34m10\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_29 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │            \u001b[38;5;34m10\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_30 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │            \u001b[38;5;34m10\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_31 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │            \u001b[38;5;34m10\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_32 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │            \u001b[38;5;34m10\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_33 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │            \u001b[38;5;34m10\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_34 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │            \u001b[38;5;34m10\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_35 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │            \u001b[38;5;34m10\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_36 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │            \u001b[38;5;34m10\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_37 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │            \u001b[38;5;34m10\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_38 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │            \u001b[38;5;34m10\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m5\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">135</span> (540.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m135\u001b[0m (540.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">135</span> (540.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m135\u001b[0m (540.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the model\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(1, (3, 3), padding='valid', input_shape=(28, 28, 1)))\n",
    "model.add(layers.Conv2D(1, (3, 3), padding='valid'))\n",
    "model.add(layers.Conv2D(1, (3, 3), padding='valid'))\n",
    "model.add(layers.Conv2D(1, (3, 3), padding='valid'))\n",
    "model.add(layers.Conv2D(1, (3, 3), padding='valid'))\n",
    "model.add(layers.Conv2D(1, (3, 3), padding='valid'))\n",
    "model.add(layers.Conv2D(1, (3, 3), padding='valid'))\n",
    "model.add(layers.Conv2D(1, (3, 3), padding='valid'))\n",
    "model.add(layers.Conv2D(1, (3, 3), padding='valid'))\n",
    "model.add(layers.Conv2D(1, (3, 3), padding='valid'))\n",
    "model.add(layers.Conv2D(1, (3, 3), padding='valid'))\n",
    "model.add(layers.Conv2D(1, (3, 3), padding='valid'))\n",
    "model.add(layers.Conv2D(1, (3, 3), padding='valid'))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1, activation='sigmoid'))  \n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',               \n",
    "    loss='binary_crossentropy',    \n",
    "    metrics=['accuracy']           \n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.808738  ]\n",
      " [-0.09997004]\n",
      " [ 0.46751595]\n",
      " [-0.8077531 ]]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "array([[-0.5488326 ],\n",
    "       [-0.24968517],\n",
    "       [ 0.74934745],\n",
    "       [-0.95130086]], dtype=float32)\n",
    "'''\n",
    "x=model.layers[14].get_weights()[0]\n",
    "print((x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded weights for layer 0 from ../../generateModelWeights_week4/InitWeightsSeries\\layer_number_0.npz\n",
      "Loaded weights for layer 1 from ../../generateModelWeights_week4/InitWeightsSeries\\layer_number_1.npz\n",
      "Loaded weights for layer 2 from ../../generateModelWeights_week4/InitWeightsSeries\\layer_number_2.npz\n",
      "Loaded weights for layer 3 from ../../generateModelWeights_week4/InitWeightsSeries\\layer_number_3.npz\n",
      "Loaded weights for layer 4 from ../../generateModelWeights_week4/InitWeightsSeries\\layer_number_4.npz\n",
      "Loaded weights for layer 5 from ../../generateModelWeights_week4/InitWeightsSeries\\layer_number_5.npz\n",
      "Loaded weights for layer 6 from ../../generateModelWeights_week4/InitWeightsSeries\\layer_number_6.npz\n",
      "Loaded weights for layer 7 from ../../generateModelWeights_week4/InitWeightsSeries\\layer_number_7.npz\n",
      "Loaded weights for layer 8 from ../../generateModelWeights_week4/InitWeightsSeries\\layer_number_8.npz\n",
      "Loaded weights for layer 9 from ../../generateModelWeights_week4/InitWeightsSeries\\layer_number_9.npz\n",
      "Loaded weights for layer 10 from ../../generateModelWeights_week4/InitWeightsSeries\\layer_number_10.npz\n",
      "Loaded weights for layer 11 from ../../generateModelWeights_week4/InitWeightsSeries\\layer_number_11.npz\n",
      "Loaded weights for layer 12 from ../../generateModelWeights_week4/InitWeightsSeries\\layer_number_12.npz\n",
      "No weights found for layer 13.\n",
      "Loaded weights for layer 14 from ../../generateModelWeights_week4/InitWeightsSeries\\layer_number_14.npz\n"
     ]
    }
   ],
   "source": [
    "def load_model_weights(model, weight_dir=\"../../generateModelWeights_week4/InitWeightsSeries\"):\n",
    "    \n",
    "    for layer_num, layer in enumerate(model.layers):\n",
    "        file_path = os.path.join(weight_dir, f\"layer_number_{layer_num}.npz\")\n",
    "        if os.path.exists(file_path):\n",
    "            loaded = np.load(file_path)\n",
    "            weights = [loaded[key] for key in loaded]\n",
    "            if layer.weights: \n",
    "                layer.set_weights(weights)\n",
    "                print(f\"Loaded weights for layer {layer_num} from {file_path}\")\n",
    "            else:\n",
    "                print(f\"Layer {layer_num} has no weights.\")\n",
    "        else:\n",
    "            print(f\"No weights found for layer {layer_num}.\")\n",
    "\n",
    "load_model_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.5488326 ]\n",
      " [-0.24968517]\n",
      " [ 0.74934745]\n",
      " [-0.95130086]]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Should match\n",
    "array([[-0.5488326 ],\n",
    "       [-0.24968517],\n",
    "       [ 0.74934745],\n",
    "       [-0.95130086]], dtype=float32)\n",
    "'''\n",
    "initial_kernels = [model.layers[i].get_weights()[0] for i in range(13)]\n",
    "\n",
    "x=model.layers[14].get_weights()[0]\n",
    "print((x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveWeightsCallback(callbacks.Callback):\n",
    "    def __init__(self, save_dir):\n",
    "        super(SaveWeightsCallback, self).__init__()\n",
    "        self.save_dir = save_dir\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch_dir = os.path.join(self.save_dir, f\"AfterEpoch{epoch + 1}\")\n",
    "        if not os.path.exists(epoch_dir):\n",
    "            os.makedirs(epoch_dir)\n",
    "        \n",
    "        for layer_num, layer in enumerate(self.model.layers):\n",
    "            if layer.weights:  # Only save weights for layers that have weights\n",
    "                file_path = os.path.join(epoch_dir, f\"Layer_{layer_num}.npz\")\n",
    "                weights = layer.get_weights()\n",
    "                np.savez(file_path, *weights)\n",
    "                print(f\"Saved weights for layer {layer_num} to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"./OneModelWeightsTraining\"\n",
    "save_weights_callback = SaveWeightsCallback(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m335/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5591 - loss: 2.5085Saved weights for layer 0 to ./OneModelWeightsTraining\\AfterEpoch1\\Layer_0.npz\n",
      "Saved weights for layer 1 to ./OneModelWeightsTraining\\AfterEpoch1\\Layer_1.npz\n",
      "Saved weights for layer 2 to ./OneModelWeightsTraining\\AfterEpoch1\\Layer_2.npz\n",
      "Saved weights for layer 3 to ./OneModelWeightsTraining\\AfterEpoch1\\Layer_3.npz\n",
      "Saved weights for layer 4 to ./OneModelWeightsTraining\\AfterEpoch1\\Layer_4.npz\n",
      "Saved weights for layer 5 to ./OneModelWeightsTraining\\AfterEpoch1\\Layer_5.npz\n",
      "Saved weights for layer 6 to ./OneModelWeightsTraining\\AfterEpoch1\\Layer_6.npz\n",
      "Saved weights for layer 7 to ./OneModelWeightsTraining\\AfterEpoch1\\Layer_7.npz\n",
      "Saved weights for layer 8 to ./OneModelWeightsTraining\\AfterEpoch1\\Layer_8.npz\n",
      "Saved weights for layer 9 to ./OneModelWeightsTraining\\AfterEpoch1\\Layer_9.npz\n",
      "Saved weights for layer 10 to ./OneModelWeightsTraining\\AfterEpoch1\\Layer_10.npz\n",
      "Saved weights for layer 11 to ./OneModelWeightsTraining\\AfterEpoch1\\Layer_11.npz\n",
      "Saved weights for layer 12 to ./OneModelWeightsTraining\\AfterEpoch1\\Layer_12.npz\n",
      "Saved weights for layer 14 to ./OneModelWeightsTraining\\AfterEpoch1\\Layer_14.npz\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.5599 - loss: 2.4940\n",
      "Epoch 2/10\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8788 - loss: 0.3013Saved weights for layer 0 to ./OneModelWeightsTraining\\AfterEpoch2\\Layer_0.npz\n",
      "Saved weights for layer 1 to ./OneModelWeightsTraining\\AfterEpoch2\\Layer_1.npz\n",
      "Saved weights for layer 2 to ./OneModelWeightsTraining\\AfterEpoch2\\Layer_2.npz\n",
      "Saved weights for layer 3 to ./OneModelWeightsTraining\\AfterEpoch2\\Layer_3.npz\n",
      "Saved weights for layer 4 to ./OneModelWeightsTraining\\AfterEpoch2\\Layer_4.npz\n",
      "Saved weights for layer 5 to ./OneModelWeightsTraining\\AfterEpoch2\\Layer_5.npz\n",
      "Saved weights for layer 6 to ./OneModelWeightsTraining\\AfterEpoch2\\Layer_6.npz\n",
      "Saved weights for layer 7 to ./OneModelWeightsTraining\\AfterEpoch2\\Layer_7.npz\n",
      "Saved weights for layer 8 to ./OneModelWeightsTraining\\AfterEpoch2\\Layer_8.npz\n",
      "Saved weights for layer 9 to ./OneModelWeightsTraining\\AfterEpoch2\\Layer_9.npz\n",
      "Saved weights for layer 10 to ./OneModelWeightsTraining\\AfterEpoch2\\Layer_10.npz\n",
      "Saved weights for layer 11 to ./OneModelWeightsTraining\\AfterEpoch2\\Layer_11.npz\n",
      "Saved weights for layer 12 to ./OneModelWeightsTraining\\AfterEpoch2\\Layer_12.npz\n",
      "Saved weights for layer 14 to ./OneModelWeightsTraining\\AfterEpoch2\\Layer_14.npz\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.8789 - loss: 0.3011\n",
      "Epoch 3/10\n",
      "\u001b[1m334/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9585 - loss: 0.1285Saved weights for layer 0 to ./OneModelWeightsTraining\\AfterEpoch3\\Layer_0.npz\n",
      "Saved weights for layer 1 to ./OneModelWeightsTraining\\AfterEpoch3\\Layer_1.npz\n",
      "Saved weights for layer 2 to ./OneModelWeightsTraining\\AfterEpoch3\\Layer_2.npz\n",
      "Saved weights for layer 3 to ./OneModelWeightsTraining\\AfterEpoch3\\Layer_3.npz\n",
      "Saved weights for layer 4 to ./OneModelWeightsTraining\\AfterEpoch3\\Layer_4.npz\n",
      "Saved weights for layer 5 to ./OneModelWeightsTraining\\AfterEpoch3\\Layer_5.npz\n",
      "Saved weights for layer 6 to ./OneModelWeightsTraining\\AfterEpoch3\\Layer_6.npz\n",
      "Saved weights for layer 7 to ./OneModelWeightsTraining\\AfterEpoch3\\Layer_7.npz\n",
      "Saved weights for layer 8 to ./OneModelWeightsTraining\\AfterEpoch3\\Layer_8.npz\n",
      "Saved weights for layer 9 to ./OneModelWeightsTraining\\AfterEpoch3\\Layer_9.npz\n",
      "Saved weights for layer 10 to ./OneModelWeightsTraining\\AfterEpoch3\\Layer_10.npz\n",
      "Saved weights for layer 11 to ./OneModelWeightsTraining\\AfterEpoch3\\Layer_11.npz\n",
      "Saved weights for layer 12 to ./OneModelWeightsTraining\\AfterEpoch3\\Layer_12.npz\n",
      "Saved weights for layer 14 to ./OneModelWeightsTraining\\AfterEpoch3\\Layer_14.npz\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9586 - loss: 0.1285\n",
      "Epoch 4/10\n",
      "\u001b[1m336/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9546 - loss: 0.1308Saved weights for layer 0 to ./OneModelWeightsTraining\\AfterEpoch4\\Layer_0.npz\n",
      "Saved weights for layer 1 to ./OneModelWeightsTraining\\AfterEpoch4\\Layer_1.npz\n",
      "Saved weights for layer 2 to ./OneModelWeightsTraining\\AfterEpoch4\\Layer_2.npz\n",
      "Saved weights for layer 3 to ./OneModelWeightsTraining\\AfterEpoch4\\Layer_3.npz\n",
      "Saved weights for layer 4 to ./OneModelWeightsTraining\\AfterEpoch4\\Layer_4.npz\n",
      "Saved weights for layer 5 to ./OneModelWeightsTraining\\AfterEpoch4\\Layer_5.npz\n",
      "Saved weights for layer 6 to ./OneModelWeightsTraining\\AfterEpoch4\\Layer_6.npz\n",
      "Saved weights for layer 7 to ./OneModelWeightsTraining\\AfterEpoch4\\Layer_7.npz\n",
      "Saved weights for layer 8 to ./OneModelWeightsTraining\\AfterEpoch4\\Layer_8.npz\n",
      "Saved weights for layer 9 to ./OneModelWeightsTraining\\AfterEpoch4\\Layer_9.npz\n",
      "Saved weights for layer 10 to ./OneModelWeightsTraining\\AfterEpoch4\\Layer_10.npz\n",
      "Saved weights for layer 11 to ./OneModelWeightsTraining\\AfterEpoch4\\Layer_11.npz\n",
      "Saved weights for layer 12 to ./OneModelWeightsTraining\\AfterEpoch4\\Layer_12.npz\n",
      "Saved weights for layer 14 to ./OneModelWeightsTraining\\AfterEpoch4\\Layer_14.npz\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9547 - loss: 0.1307\n",
      "Epoch 5/10\n",
      "\u001b[1m336/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9643 - loss: 0.1091Saved weights for layer 0 to ./OneModelWeightsTraining\\AfterEpoch5\\Layer_0.npz\n",
      "Saved weights for layer 1 to ./OneModelWeightsTraining\\AfterEpoch5\\Layer_1.npz\n",
      "Saved weights for layer 2 to ./OneModelWeightsTraining\\AfterEpoch5\\Layer_2.npz\n",
      "Saved weights for layer 3 to ./OneModelWeightsTraining\\AfterEpoch5\\Layer_3.npz\n",
      "Saved weights for layer 4 to ./OneModelWeightsTraining\\AfterEpoch5\\Layer_4.npz\n",
      "Saved weights for layer 5 to ./OneModelWeightsTraining\\AfterEpoch5\\Layer_5.npz\n",
      "Saved weights for layer 6 to ./OneModelWeightsTraining\\AfterEpoch5\\Layer_6.npz\n",
      "Saved weights for layer 7 to ./OneModelWeightsTraining\\AfterEpoch5\\Layer_7.npz\n",
      "Saved weights for layer 8 to ./OneModelWeightsTraining\\AfterEpoch5\\Layer_8.npz\n",
      "Saved weights for layer 9 to ./OneModelWeightsTraining\\AfterEpoch5\\Layer_9.npz\n",
      "Saved weights for layer 10 to ./OneModelWeightsTraining\\AfterEpoch5\\Layer_10.npz\n",
      "Saved weights for layer 11 to ./OneModelWeightsTraining\\AfterEpoch5\\Layer_11.npz\n",
      "Saved weights for layer 12 to ./OneModelWeightsTraining\\AfterEpoch5\\Layer_12.npz\n",
      "Saved weights for layer 14 to ./OneModelWeightsTraining\\AfterEpoch5\\Layer_14.npz\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9643 - loss: 0.1091\n",
      "Epoch 6/10\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9654 - loss: 0.1147Saved weights for layer 0 to ./OneModelWeightsTraining\\AfterEpoch6\\Layer_0.npz\n",
      "Saved weights for layer 1 to ./OneModelWeightsTraining\\AfterEpoch6\\Layer_1.npz\n",
      "Saved weights for layer 2 to ./OneModelWeightsTraining\\AfterEpoch6\\Layer_2.npz\n",
      "Saved weights for layer 3 to ./OneModelWeightsTraining\\AfterEpoch6\\Layer_3.npz\n",
      "Saved weights for layer 4 to ./OneModelWeightsTraining\\AfterEpoch6\\Layer_4.npz\n",
      "Saved weights for layer 5 to ./OneModelWeightsTraining\\AfterEpoch6\\Layer_5.npz\n",
      "Saved weights for layer 6 to ./OneModelWeightsTraining\\AfterEpoch6\\Layer_6.npz\n",
      "Saved weights for layer 7 to ./OneModelWeightsTraining\\AfterEpoch6\\Layer_7.npz\n",
      "Saved weights for layer 8 to ./OneModelWeightsTraining\\AfterEpoch6\\Layer_8.npz\n",
      "Saved weights for layer 9 to ./OneModelWeightsTraining\\AfterEpoch6\\Layer_9.npz\n",
      "Saved weights for layer 10 to ./OneModelWeightsTraining\\AfterEpoch6\\Layer_10.npz\n",
      "Saved weights for layer 11 to ./OneModelWeightsTraining\\AfterEpoch6\\Layer_11.npz\n",
      "Saved weights for layer 12 to ./OneModelWeightsTraining\\AfterEpoch6\\Layer_12.npz\n",
      "Saved weights for layer 14 to ./OneModelWeightsTraining\\AfterEpoch6\\Layer_14.npz\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.9654 - loss: 0.1146\n",
      "Epoch 7/10\n",
      "\u001b[1m337/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9662 - loss: 0.1029Saved weights for layer 0 to ./OneModelWeightsTraining\\AfterEpoch7\\Layer_0.npz\n",
      "Saved weights for layer 1 to ./OneModelWeightsTraining\\AfterEpoch7\\Layer_1.npz\n",
      "Saved weights for layer 2 to ./OneModelWeightsTraining\\AfterEpoch7\\Layer_2.npz\n",
      "Saved weights for layer 3 to ./OneModelWeightsTraining\\AfterEpoch7\\Layer_3.npz\n",
      "Saved weights for layer 4 to ./OneModelWeightsTraining\\AfterEpoch7\\Layer_4.npz\n",
      "Saved weights for layer 5 to ./OneModelWeightsTraining\\AfterEpoch7\\Layer_5.npz\n",
      "Saved weights for layer 6 to ./OneModelWeightsTraining\\AfterEpoch7\\Layer_6.npz\n",
      "Saved weights for layer 7 to ./OneModelWeightsTraining\\AfterEpoch7\\Layer_7.npz\n",
      "Saved weights for layer 8 to ./OneModelWeightsTraining\\AfterEpoch7\\Layer_8.npz\n",
      "Saved weights for layer 9 to ./OneModelWeightsTraining\\AfterEpoch7\\Layer_9.npz\n",
      "Saved weights for layer 10 to ./OneModelWeightsTraining\\AfterEpoch7\\Layer_10.npz\n",
      "Saved weights for layer 11 to ./OneModelWeightsTraining\\AfterEpoch7\\Layer_11.npz\n",
      "Saved weights for layer 12 to ./OneModelWeightsTraining\\AfterEpoch7\\Layer_12.npz\n",
      "Saved weights for layer 14 to ./OneModelWeightsTraining\\AfterEpoch7\\Layer_14.npz\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.9662 - loss: 0.1029\n",
      "Epoch 8/10\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9680 - loss: 0.1033Saved weights for layer 0 to ./OneModelWeightsTraining\\AfterEpoch8\\Layer_0.npz\n",
      "Saved weights for layer 1 to ./OneModelWeightsTraining\\AfterEpoch8\\Layer_1.npz\n",
      "Saved weights for layer 2 to ./OneModelWeightsTraining\\AfterEpoch8\\Layer_2.npz\n",
      "Saved weights for layer 3 to ./OneModelWeightsTraining\\AfterEpoch8\\Layer_3.npz\n",
      "Saved weights for layer 4 to ./OneModelWeightsTraining\\AfterEpoch8\\Layer_4.npz\n",
      "Saved weights for layer 5 to ./OneModelWeightsTraining\\AfterEpoch8\\Layer_5.npz\n",
      "Saved weights for layer 6 to ./OneModelWeightsTraining\\AfterEpoch8\\Layer_6.npz\n",
      "Saved weights for layer 7 to ./OneModelWeightsTraining\\AfterEpoch8\\Layer_7.npz\n",
      "Saved weights for layer 8 to ./OneModelWeightsTraining\\AfterEpoch8\\Layer_8.npz\n",
      "Saved weights for layer 9 to ./OneModelWeightsTraining\\AfterEpoch8\\Layer_9.npz\n",
      "Saved weights for layer 10 to ./OneModelWeightsTraining\\AfterEpoch8\\Layer_10.npz\n",
      "Saved weights for layer 11 to ./OneModelWeightsTraining\\AfterEpoch8\\Layer_11.npz\n",
      "Saved weights for layer 12 to ./OneModelWeightsTraining\\AfterEpoch8\\Layer_12.npz\n",
      "Saved weights for layer 14 to ./OneModelWeightsTraining\\AfterEpoch8\\Layer_14.npz\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9680 - loss: 0.1033\n",
      "Epoch 9/10\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9671 - loss: 0.1053Saved weights for layer 0 to ./OneModelWeightsTraining\\AfterEpoch9\\Layer_0.npz\n",
      "Saved weights for layer 1 to ./OneModelWeightsTraining\\AfterEpoch9\\Layer_1.npz\n",
      "Saved weights for layer 2 to ./OneModelWeightsTraining\\AfterEpoch9\\Layer_2.npz\n",
      "Saved weights for layer 3 to ./OneModelWeightsTraining\\AfterEpoch9\\Layer_3.npz\n",
      "Saved weights for layer 4 to ./OneModelWeightsTraining\\AfterEpoch9\\Layer_4.npz\n",
      "Saved weights for layer 5 to ./OneModelWeightsTraining\\AfterEpoch9\\Layer_5.npz\n",
      "Saved weights for layer 6 to ./OneModelWeightsTraining\\AfterEpoch9\\Layer_6.npz\n",
      "Saved weights for layer 7 to ./OneModelWeightsTraining\\AfterEpoch9\\Layer_7.npz\n",
      "Saved weights for layer 8 to ./OneModelWeightsTraining\\AfterEpoch9\\Layer_8.npz\n",
      "Saved weights for layer 9 to ./OneModelWeightsTraining\\AfterEpoch9\\Layer_9.npz\n",
      "Saved weights for layer 10 to ./OneModelWeightsTraining\\AfterEpoch9\\Layer_10.npz\n",
      "Saved weights for layer 11 to ./OneModelWeightsTraining\\AfterEpoch9\\Layer_11.npz\n",
      "Saved weights for layer 12 to ./OneModelWeightsTraining\\AfterEpoch9\\Layer_12.npz\n",
      "Saved weights for layer 14 to ./OneModelWeightsTraining\\AfterEpoch9\\Layer_14.npz\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.9671 - loss: 0.1053\n",
      "Epoch 10/10\n",
      "\u001b[1m337/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9697 - loss: 0.1011Saved weights for layer 0 to ./OneModelWeightsTraining\\AfterEpoch10\\Layer_0.npz\n",
      "Saved weights for layer 1 to ./OneModelWeightsTraining\\AfterEpoch10\\Layer_1.npz\n",
      "Saved weights for layer 2 to ./OneModelWeightsTraining\\AfterEpoch10\\Layer_2.npz\n",
      "Saved weights for layer 3 to ./OneModelWeightsTraining\\AfterEpoch10\\Layer_3.npz\n",
      "Saved weights for layer 4 to ./OneModelWeightsTraining\\AfterEpoch10\\Layer_4.npz\n",
      "Saved weights for layer 5 to ./OneModelWeightsTraining\\AfterEpoch10\\Layer_5.npz\n",
      "Saved weights for layer 6 to ./OneModelWeightsTraining\\AfterEpoch10\\Layer_6.npz\n",
      "Saved weights for layer 7 to ./OneModelWeightsTraining\\AfterEpoch10\\Layer_7.npz\n",
      "Saved weights for layer 8 to ./OneModelWeightsTraining\\AfterEpoch10\\Layer_8.npz\n",
      "Saved weights for layer 9 to ./OneModelWeightsTraining\\AfterEpoch10\\Layer_9.npz\n",
      "Saved weights for layer 10 to ./OneModelWeightsTraining\\AfterEpoch10\\Layer_10.npz\n",
      "Saved weights for layer 11 to ./OneModelWeightsTraining\\AfterEpoch10\\Layer_11.npz\n",
      "Saved weights for layer 12 to ./OneModelWeightsTraining\\AfterEpoch10\\Layer_12.npz\n",
      "Saved weights for layer 14 to ./OneModelWeightsTraining\\AfterEpoch10\\Layer_14.npz\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.9697 - loss: 0.1011\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=10,  \n",
    "    callbacks=[save_weights_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Accuracy = 0.6299\n",
      "Epoch 2: Accuracy = 0.9139\n",
      "Epoch 3: Accuracy = 0.9595\n",
      "Epoch 4: Accuracy = 0.9634\n",
      "Epoch 5: Accuracy = 0.9649\n",
      "Epoch 6: Accuracy = 0.9665\n",
      "Epoch 7: Accuracy = 0.9671\n",
      "Epoch 8: Accuracy = 0.9685\n",
      "Epoch 9: Accuracy = 0.9685\n",
      "Epoch 10: Accuracy = 0.9687\n"
     ]
    }
   ],
   "source": [
    "for epoch, accuracy in enumerate(history.history['accuracy'], 1):\n",
    "    print(f\"Epoch {epoch}: Accuracy = {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9681 - loss: 0.1113\n",
      "Test accuracy: 0.9734567999839783\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_kernels = [model.layers[i].get_weights()[0] for i in range(13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_kernels(before_weights, after_weights, layer_num, vmin, vmax):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    \n",
    "    # Heatmap for weights before training\n",
    "    sns.heatmap(before_weights, ax=axes[0], cmap=\"coolwarm\", cbar=False, vmin=vmin, vmax=vmax, annot=True)\n",
    "    axes[0].set_title(f'Layer {layer_num} - Before Training')\n",
    "\n",
    "    # Heatmap for weights after training\n",
    "    sns.heatmap(after_weights, ax=axes[1], cmap=\"coolwarm\", cbar=False, vmin=vmin, vmax=vmax, annot=True)\n",
    "    axes[1].set_title(f'Layer {layer_num} - After Training')\n",
    "\n",
    "    # Save the figure\n",
    "    plt.savefig(f'kernel_{layer_num}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(13):\n",
    "    # Extract kernels for the first input channel (assuming input has only 1 channel)\n",
    "    initial_kernel = initial_kernels[i][:, :, 0, 0]  # Extract the 2D kernel\n",
    "    final_kernel = final_kernels[i][:, :, 0, 0]\n",
    "    \n",
    "    # Ensure the same color range for both heatmaps\n",
    "    vmin = min(initial_kernel.min(), final_kernel.min())\n",
    "    vmax = max(initial_kernel.max(), final_kernel.max())\n",
    "\n",
    "    # Save the comparison as an image file with consistent color range\n",
    "    save_kernels(initial_kernel, final_kernel, i + 1, vmin, vmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum all kernel weights after training\n",
    "kernel_sum = np.zeros_like(final_kernels[0][:, :, 0, 0])  # Initialize with zeros\n",
    "for i in range(13):\n",
    "    kernel_sum += final_kernels[i][:, :, 0, 0]  # Sum each kernel\n",
    "\n",
    "# Plot the summed kernel heatmap\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(kernel_sum, cmap=\"coolwarm\", annot=True, cbar=True)\n",
    "plt.title('Summed Kernel Weights After Training')\n",
    "plt.savefig('summed_kernel_weights.png')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
