{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from tensorflow.keras.callbacks import Callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the dataset\n",
    "mnist = keras.datasets.mnist\n",
    "(x_full, y_full), (x_test_full, y_test_full) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape_training_0 =>\n",
      "\t (5400, 28, 28)\n",
      "\t (5400,)\n",
      "lenght_training_other =>\n",
      "\t 9 9\n",
      "shape_training_other =>\n",
      "\t (5400, 28, 28)\n",
      "\t (5400,)\n",
      "shape_training_complete =>\n",
      "\t (10800, 28, 28)\n",
      "\t (10800,)\n"
     ]
    }
   ],
   "source": [
    "# Training Data\n",
    "'''\n",
    "TRAINING DATA\n",
    "5400 - ones\n",
    "5400 - other \n",
    "    [600 * 9 of 1/0 to 9]\n",
    "'''\n",
    "\n",
    "x_train_0 = x_full[y_full == 1][:5400]\n",
    "y_train_0 = np.ones((5400,))\n",
    "print(\"shape_training_0 =>\")\n",
    "print(\"\\t\",x_train_0.shape)\n",
    "print(\"\\t\",y_train_0.shape)\n",
    "\n",
    "x_train_others = []\n",
    "y_train_others = []\n",
    "\n",
    "x_digit = x_full[y_full == 0][:600]\n",
    "y_digit = np.zeros((600,))  \n",
    "x_train_others.append(x_digit)\n",
    "y_train_others.append(y_digit)\n",
    "\n",
    "for digit in range(2,10):\n",
    "    x_digit = x_full[y_full == digit][:600]\n",
    "    y_digit = np.zeros((600,))  \n",
    "    x_train_others.append(x_digit)\n",
    "    y_train_others.append(y_digit)\n",
    "print(\"lenght_training_other =>\")\n",
    "print(\"\\t\",len(x_train_others),len(y_train_others))\n",
    "\n",
    "x_train_others = np.concatenate(x_train_others, axis=0)\n",
    "y_train_others = np.concatenate(y_train_others, axis=0)\n",
    "print(\"shape_training_other =>\")\n",
    "print(\"\\t\",x_train_others.shape)\n",
    "print(\"\\t\",y_train_others.shape)\n",
    "\n",
    "x_train = np.concatenate([x_train_0, x_train_others], axis=0)\n",
    "y_train = np.concatenate([y_train_0, y_train_others], axis=0)\n",
    "x_train, y_train = shuffle(x_train, y_train, random_state=42)\n",
    "print(\"shape_training_complete =>\")\n",
    "print(\"\\t\",x_train.shape)\n",
    "print(\"\\t\",y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape_testing_0 =>\n",
      "\t (810, 28, 28)\n",
      "\t (810,)\n",
      "lenght_testing_other =>\n",
      "\t 9 9\n",
      "shape_testing_other =>\n",
      "\t (810, 28, 28)\n",
      "\t (810,)\n",
      "shape_testing_complete =>\n",
      "\t (1620, 28, 28)\n",
      "\t (1620,)\n"
     ]
    }
   ],
   "source": [
    "# Testing Data\n",
    "'''\n",
    "TESTING DATA\n",
    "810 - ones\n",
    "810 - other \n",
    "    [90 * 9 of 1/0 to 9]\n",
    "'''\n",
    "\n",
    "x_test_0 = x_test_full[y_test_full == 1][:810]\n",
    "y_test_0 = np.ones((810,))\n",
    "print(\"shape_testing_0 =>\")\n",
    "print(\"\\t\",x_test_0.shape)\n",
    "print(\"\\t\",y_test_0.shape)\n",
    "\n",
    "x_test_others = []\n",
    "y_test_others = []\n",
    "x_digit = x_test_full[y_test_full == 0][:90]\n",
    "y_digit = np.zeros((90,))  \n",
    "x_test_others.append(x_digit)\n",
    "y_test_others.append(y_digit)\n",
    "for digit in range(2,10):\n",
    "    x_digit = x_test_full[y_test_full == digit][:90]\n",
    "    y_digit = np.zeros((90,))  \n",
    "    x_test_others.append(x_digit)\n",
    "    y_test_others.append(y_digit)\n",
    "print(\"lenght_testing_other =>\")\n",
    "print(\"\\t\",len(x_test_others),len(y_test_others))\n",
    "\n",
    "x_test_others = np.concatenate(x_test_others, axis=0)\n",
    "y_test_others = np.concatenate(y_test_others, axis=0)\n",
    "print(\"shape_testing_other =>\")\n",
    "print(\"\\t\",x_test_others.shape)\n",
    "print(\"\\t\",y_test_others.shape)\n",
    "\n",
    "\n",
    "x_test = np.concatenate([x_test_0, x_test_others], axis=0)\n",
    "y_test = np.concatenate([y_test_0, y_test_others], axis=0)\n",
    "x_test, y_test = shuffle(x_test, y_test, random_state=42)\n",
    "print(\"shape_testing_complete =>\")\n",
    "print(\"\\t\",x_test.shape)\n",
    "print(\"\\t\",y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nandi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">169</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">14,450</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,612</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">903</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">242</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │            \u001b[38;5;34m10\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m169\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m85\u001b[0m)             │        \u001b[38;5;34m14,450\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m)             │         \u001b[38;5;34m3,612\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)             │           \u001b[38;5;34m903\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)             │           \u001b[38;5;34m242\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │            \u001b[38;5;34m60\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m18\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m8\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m3\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,306</span> (75.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,306\u001b[0m (75.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,306</span> (75.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,306\u001b[0m (75.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the model\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(1, (3, 3), padding='valid', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(85, activation='relu'))\n",
    "model.add(layers.Dense(42, activation='relu'))\n",
    "model.add(layers.Dense(21, activation='relu'))\n",
    "model.add(layers.Dense(11, activation='relu'))\n",
    "model.add(layers.Dense(5, activation='relu'))\n",
    "model.add(layers.Dense(3, activation='relu'))\n",
    "model.add(layers.Dense(2, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))  \n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',               \n",
    "    loss='binary_crossentropy',    \n",
    "    metrics=['accuracy']           \n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4227774]\n",
      " [1.3591698]]\n"
     ]
    }
   ],
   "source": [
    "x=model.get_weights()[16]\n",
    "print((x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded weights for layer 0 from ./generateModelWeights/InitWeights\\layer_number_0.npz\n",
      "No weights found for layer 1.\n",
      "No weights found for layer 2.\n",
      "Loaded weights for layer 3 from ./generateModelWeights/InitWeights\\layer_number_3.npz\n",
      "Loaded weights for layer 4 from ./generateModelWeights/InitWeights\\layer_number_4.npz\n",
      "Loaded weights for layer 5 from ./generateModelWeights/InitWeights\\layer_number_5.npz\n",
      "Loaded weights for layer 6 from ./generateModelWeights/InitWeights\\layer_number_6.npz\n",
      "Loaded weights for layer 7 from ./generateModelWeights/InitWeights\\layer_number_7.npz\n",
      "Loaded weights for layer 8 from ./generateModelWeights/InitWeights\\layer_number_8.npz\n",
      "Loaded weights for layer 9 from ./generateModelWeights/InitWeights\\layer_number_9.npz\n",
      "Loaded weights for layer 10 from ./generateModelWeights/InitWeights\\layer_number_10.npz\n"
     ]
    }
   ],
   "source": [
    "def load_model_weights(model, weight_dir=\"./generateModelWeights/InitWeights\"):\n",
    "    \n",
    "    for layer_num, layer in enumerate(model.layers):\n",
    "        file_path = os.path.join(weight_dir, f\"layer_number_{layer_num}.npz\")\n",
    "        if os.path.exists(file_path):\n",
    "            loaded = np.load(file_path)\n",
    "            weights = [loaded[key] for key in loaded]\n",
    "            if layer.weights: \n",
    "                layer.set_weights(weights)\n",
    "                print(f\"Loaded weights for layer {layer_num} from {file_path}\")\n",
    "            else:\n",
    "                print(f\"Layer {layer_num} has no weights.\")\n",
    "        else:\n",
    "            print(f\"No weights found for layer {layer_num}.\")\n",
    "\n",
    "load_model_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5173087]\n",
      " [0.5407704]]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Should match\n",
    "[[0.5173087]\n",
    " [0.5407704]]\n",
    "'''\n",
    "x=model.get_weights()[16]\n",
    "print((x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveWeightsCallback(callbacks.Callback):\n",
    "    def __init__(self, save_dir):\n",
    "        super(SaveWeightsCallback, self).__init__()\n",
    "        self.save_dir = save_dir\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch_dir = os.path.join(self.save_dir, f\"AfterEpoch{epoch + 1}\")\n",
    "        if not os.path.exists(epoch_dir):\n",
    "            os.makedirs(epoch_dir)\n",
    "        \n",
    "        for layer_num, layer in enumerate(self.model.layers):\n",
    "            if layer.weights:  # Only save weights for layers that have weights\n",
    "                file_path = os.path.join(epoch_dir, f\"Layer_{layer_num}.npz\")\n",
    "                weights = layer.get_weights()\n",
    "                np.savez(file_path, *weights)\n",
    "                print(f\"Saved weights for layer {layer_num} to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"./OneModelWeightsTraining\"\n",
    "save_weights_callback = SaveWeightsCallback(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m306/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8629 - loss: 0.4664Saved weights for layer 0 to ./OneModelWeightsTraining\\AfterEpoch1\\Layer_0.npz\n",
      "Saved weights for layer 3 to ./OneModelWeightsTraining\\AfterEpoch1\\Layer_3.npz\n",
      "Saved weights for layer 4 to ./OneModelWeightsTraining\\AfterEpoch1\\Layer_4.npz\n",
      "Saved weights for layer 5 to ./OneModelWeightsTraining\\AfterEpoch1\\Layer_5.npz\n",
      "Saved weights for layer 6 to ./OneModelWeightsTraining\\AfterEpoch1\\Layer_6.npz\n",
      "Saved weights for layer 7 to ./OneModelWeightsTraining\\AfterEpoch1\\Layer_7.npz\n",
      "Saved weights for layer 8 to ./OneModelWeightsTraining\\AfterEpoch1\\Layer_8.npz\n",
      "Saved weights for layer 9 to ./OneModelWeightsTraining\\AfterEpoch1\\Layer_9.npz\n",
      "Saved weights for layer 10 to ./OneModelWeightsTraining\\AfterEpoch1\\Layer_10.npz\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8697 - loss: 0.4584\n",
      "Epoch 2/10\n",
      "\u001b[1m332/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9769 - loss: 0.2864Saved weights for layer 0 to ./OneModelWeightsTraining\\AfterEpoch2\\Layer_0.npz\n",
      "Saved weights for layer 3 to ./OneModelWeightsTraining\\AfterEpoch2\\Layer_3.npz\n",
      "Saved weights for layer 4 to ./OneModelWeightsTraining\\AfterEpoch2\\Layer_4.npz\n",
      "Saved weights for layer 5 to ./OneModelWeightsTraining\\AfterEpoch2\\Layer_5.npz\n",
      "Saved weights for layer 6 to ./OneModelWeightsTraining\\AfterEpoch2\\Layer_6.npz\n",
      "Saved weights for layer 7 to ./OneModelWeightsTraining\\AfterEpoch2\\Layer_7.npz\n",
      "Saved weights for layer 8 to ./OneModelWeightsTraining\\AfterEpoch2\\Layer_8.npz\n",
      "Saved weights for layer 9 to ./OneModelWeightsTraining\\AfterEpoch2\\Layer_9.npz\n",
      "Saved weights for layer 10 to ./OneModelWeightsTraining\\AfterEpoch2\\Layer_10.npz\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9769 - loss: 0.2861\n",
      "Epoch 3/10\n",
      "\u001b[1m328/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9824 - loss: 0.2282Saved weights for layer 0 to ./OneModelWeightsTraining\\AfterEpoch3\\Layer_0.npz\n",
      "Saved weights for layer 3 to ./OneModelWeightsTraining\\AfterEpoch3\\Layer_3.npz\n",
      "Saved weights for layer 4 to ./OneModelWeightsTraining\\AfterEpoch3\\Layer_4.npz\n",
      "Saved weights for layer 5 to ./OneModelWeightsTraining\\AfterEpoch3\\Layer_5.npz\n",
      "Saved weights for layer 6 to ./OneModelWeightsTraining\\AfterEpoch3\\Layer_6.npz\n",
      "Saved weights for layer 7 to ./OneModelWeightsTraining\\AfterEpoch3\\Layer_7.npz\n",
      "Saved weights for layer 8 to ./OneModelWeightsTraining\\AfterEpoch3\\Layer_8.npz\n",
      "Saved weights for layer 9 to ./OneModelWeightsTraining\\AfterEpoch3\\Layer_9.npz\n",
      "Saved weights for layer 10 to ./OneModelWeightsTraining\\AfterEpoch3\\Layer_10.npz\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9824 - loss: 0.2277\n",
      "Epoch 4/10\n",
      "\u001b[1m312/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9797 - loss: 0.1913Saved weights for layer 0 to ./OneModelWeightsTraining\\AfterEpoch4\\Layer_0.npz\n",
      "Saved weights for layer 3 to ./OneModelWeightsTraining\\AfterEpoch4\\Layer_3.npz\n",
      "Saved weights for layer 4 to ./OneModelWeightsTraining\\AfterEpoch4\\Layer_4.npz\n",
      "Saved weights for layer 5 to ./OneModelWeightsTraining\\AfterEpoch4\\Layer_5.npz\n",
      "Saved weights for layer 6 to ./OneModelWeightsTraining\\AfterEpoch4\\Layer_6.npz\n",
      "Saved weights for layer 7 to ./OneModelWeightsTraining\\AfterEpoch4\\Layer_7.npz\n",
      "Saved weights for layer 8 to ./OneModelWeightsTraining\\AfterEpoch4\\Layer_8.npz\n",
      "Saved weights for layer 9 to ./OneModelWeightsTraining\\AfterEpoch4\\Layer_9.npz\n",
      "Saved weights for layer 10 to ./OneModelWeightsTraining\\AfterEpoch4\\Layer_10.npz\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9801 - loss: 0.1901\n",
      "Epoch 5/10\n",
      "\u001b[1m327/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9860 - loss: 0.1532Saved weights for layer 0 to ./OneModelWeightsTraining\\AfterEpoch5\\Layer_0.npz\n",
      "Saved weights for layer 3 to ./OneModelWeightsTraining\\AfterEpoch5\\Layer_3.npz\n",
      "Saved weights for layer 4 to ./OneModelWeightsTraining\\AfterEpoch5\\Layer_4.npz\n",
      "Saved weights for layer 5 to ./OneModelWeightsTraining\\AfterEpoch5\\Layer_5.npz\n",
      "Saved weights for layer 6 to ./OneModelWeightsTraining\\AfterEpoch5\\Layer_6.npz\n",
      "Saved weights for layer 7 to ./OneModelWeightsTraining\\AfterEpoch5\\Layer_7.npz\n",
      "Saved weights for layer 8 to ./OneModelWeightsTraining\\AfterEpoch5\\Layer_8.npz\n",
      "Saved weights for layer 9 to ./OneModelWeightsTraining\\AfterEpoch5\\Layer_9.npz\n",
      "Saved weights for layer 10 to ./OneModelWeightsTraining\\AfterEpoch5\\Layer_10.npz\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9860 - loss: 0.1531\n",
      "Epoch 6/10\n",
      "\u001b[1m310/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9914 - loss: 0.1219Saved weights for layer 0 to ./OneModelWeightsTraining\\AfterEpoch6\\Layer_0.npz\n",
      "Saved weights for layer 3 to ./OneModelWeightsTraining\\AfterEpoch6\\Layer_3.npz\n",
      "Saved weights for layer 4 to ./OneModelWeightsTraining\\AfterEpoch6\\Layer_4.npz\n",
      "Saved weights for layer 5 to ./OneModelWeightsTraining\\AfterEpoch6\\Layer_5.npz\n",
      "Saved weights for layer 6 to ./OneModelWeightsTraining\\AfterEpoch6\\Layer_6.npz\n",
      "Saved weights for layer 7 to ./OneModelWeightsTraining\\AfterEpoch6\\Layer_7.npz\n",
      "Saved weights for layer 8 to ./OneModelWeightsTraining\\AfterEpoch6\\Layer_8.npz\n",
      "Saved weights for layer 9 to ./OneModelWeightsTraining\\AfterEpoch6\\Layer_9.npz\n",
      "Saved weights for layer 10 to ./OneModelWeightsTraining\\AfterEpoch6\\Layer_10.npz\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9913 - loss: 0.1217\n",
      "Epoch 7/10\n",
      "\u001b[1m313/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9936 - loss: 0.0991Saved weights for layer 0 to ./OneModelWeightsTraining\\AfterEpoch7\\Layer_0.npz\n",
      "Saved weights for layer 3 to ./OneModelWeightsTraining\\AfterEpoch7\\Layer_3.npz\n",
      "Saved weights for layer 4 to ./OneModelWeightsTraining\\AfterEpoch7\\Layer_4.npz\n",
      "Saved weights for layer 5 to ./OneModelWeightsTraining\\AfterEpoch7\\Layer_5.npz\n",
      "Saved weights for layer 6 to ./OneModelWeightsTraining\\AfterEpoch7\\Layer_6.npz\n",
      "Saved weights for layer 7 to ./OneModelWeightsTraining\\AfterEpoch7\\Layer_7.npz\n",
      "Saved weights for layer 8 to ./OneModelWeightsTraining\\AfterEpoch7\\Layer_8.npz\n",
      "Saved weights for layer 9 to ./OneModelWeightsTraining\\AfterEpoch7\\Layer_9.npz\n",
      "Saved weights for layer 10 to ./OneModelWeightsTraining\\AfterEpoch7\\Layer_10.npz\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9935 - loss: 0.0991\n",
      "Epoch 8/10\n",
      "\u001b[1m316/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9929 - loss: 0.0877Saved weights for layer 0 to ./OneModelWeightsTraining\\AfterEpoch8\\Layer_0.npz\n",
      "Saved weights for layer 3 to ./OneModelWeightsTraining\\AfterEpoch8\\Layer_3.npz\n",
      "Saved weights for layer 4 to ./OneModelWeightsTraining\\AfterEpoch8\\Layer_4.npz\n",
      "Saved weights for layer 5 to ./OneModelWeightsTraining\\AfterEpoch8\\Layer_5.npz\n",
      "Saved weights for layer 6 to ./OneModelWeightsTraining\\AfterEpoch8\\Layer_6.npz\n",
      "Saved weights for layer 7 to ./OneModelWeightsTraining\\AfterEpoch8\\Layer_7.npz\n",
      "Saved weights for layer 8 to ./OneModelWeightsTraining\\AfterEpoch8\\Layer_8.npz\n",
      "Saved weights for layer 9 to ./OneModelWeightsTraining\\AfterEpoch8\\Layer_9.npz\n",
      "Saved weights for layer 10 to ./OneModelWeightsTraining\\AfterEpoch8\\Layer_10.npz\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9929 - loss: 0.0875\n",
      "Epoch 9/10\n",
      "\u001b[1m305/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9936 - loss: 0.0777Saved weights for layer 0 to ./OneModelWeightsTraining\\AfterEpoch9\\Layer_0.npz\n",
      "Saved weights for layer 3 to ./OneModelWeightsTraining\\AfterEpoch9\\Layer_3.npz\n",
      "Saved weights for layer 4 to ./OneModelWeightsTraining\\AfterEpoch9\\Layer_4.npz\n",
      "Saved weights for layer 5 to ./OneModelWeightsTraining\\AfterEpoch9\\Layer_5.npz\n",
      "Saved weights for layer 6 to ./OneModelWeightsTraining\\AfterEpoch9\\Layer_6.npz\n",
      "Saved weights for layer 7 to ./OneModelWeightsTraining\\AfterEpoch9\\Layer_7.npz\n",
      "Saved weights for layer 8 to ./OneModelWeightsTraining\\AfterEpoch9\\Layer_8.npz\n",
      "Saved weights for layer 9 to ./OneModelWeightsTraining\\AfterEpoch9\\Layer_9.npz\n",
      "Saved weights for layer 10 to ./OneModelWeightsTraining\\AfterEpoch9\\Layer_10.npz\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9936 - loss: 0.0772\n",
      "Epoch 10/10\n",
      "\u001b[1m314/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9954 - loss: 0.0619Saved weights for layer 0 to ./OneModelWeightsTraining\\AfterEpoch10\\Layer_0.npz\n",
      "Saved weights for layer 3 to ./OneModelWeightsTraining\\AfterEpoch10\\Layer_3.npz\n",
      "Saved weights for layer 4 to ./OneModelWeightsTraining\\AfterEpoch10\\Layer_4.npz\n",
      "Saved weights for layer 5 to ./OneModelWeightsTraining\\AfterEpoch10\\Layer_5.npz\n",
      "Saved weights for layer 6 to ./OneModelWeightsTraining\\AfterEpoch10\\Layer_6.npz\n",
      "Saved weights for layer 7 to ./OneModelWeightsTraining\\AfterEpoch10\\Layer_7.npz\n",
      "Saved weights for layer 8 to ./OneModelWeightsTraining\\AfterEpoch10\\Layer_8.npz\n",
      "Saved weights for layer 9 to ./OneModelWeightsTraining\\AfterEpoch10\\Layer_9.npz\n",
      "Saved weights for layer 10 to ./OneModelWeightsTraining\\AfterEpoch10\\Layer_10.npz\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9954 - loss: 0.0617\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=10,  \n",
    "    callbacks=[save_weights_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Accuracy = 0.9344\n",
      "Epoch 2: Accuracy = 0.9785\n",
      "Epoch 3: Accuracy = 0.9827\n",
      "Epoch 4: Accuracy = 0.9842\n",
      "Epoch 5: Accuracy = 0.9851\n",
      "Epoch 6: Accuracy = 0.9902\n",
      "Epoch 7: Accuracy = 0.9924\n",
      "Epoch 8: Accuracy = 0.9933\n",
      "Epoch 9: Accuracy = 0.9938\n",
      "Epoch 10: Accuracy = 0.9953\n"
     ]
    }
   ],
   "source": [
    "for epoch, accuracy in enumerate(history.history['accuracy'], 1):\n",
    "    print(f\"Epoch {epoch}: Accuracy = {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.9911 - loss: 0.0704\n",
      "Test accuracy: 0.9932098984718323\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import save_model\n",
    "\n",
    "# Assuming 'model' is your trained model\n",
    "model.save('One_10_9_24_0052.h5')  # Saves the entire model including architecture, weights, and optimizer state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('new_one_10_9_24_0052.keras') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
